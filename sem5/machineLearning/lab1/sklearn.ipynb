{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFJbKWC7EBEh"
   },
   "source": [
    "## **BEGINNER'S TUTORIAL ON SCIKIT-LEARN**\n",
    "\n",
    "In this tutorial, we will explore some common tasks that can be accomplished using scikit-learn, a popular machine learning package in Python. Scikit-learn is known for its simplicity and efficiency in handling various machine learning algorithms. We will cover the following topics:\n",
    "\n",
    "1. Loading a dataset\n",
    "2. Splitting the dataset into training, validation, and test sets\n",
    "3. Training different classification and regression models\n",
    "4. Finding missing values in the dataset\n",
    "5. Evaluating model performance using various metrics\n",
    "\n",
    "By the end of this tutorial, you will have a good understanding of how to use scikit-learn to build and evaluate machine learning models. Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzf3IZvMEBEx"
   },
   "source": [
    "### Package Installation & Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gGko51lzEBE0",
    "outputId": "cd4794b1-3097-4d4d-db7c-c22a5a7e50ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/shreya/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in /home/shreya/miniconda3/lib/python3.12/site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in /home/shreya/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/shreya/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/shreya/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/shreya/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/shreya/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shreya/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/shreya/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/shreya/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#execute this cell to install the required packages (if not done already)\n",
    "! pip install scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbhBfli8EBE7"
   },
   "source": [
    "#### Install Kaggle API\n",
    "You need to have the Kaggle API installed. You can install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tfwsFzISEBE9",
    "outputId": "543f1f88-da3f-4ff4-a46e-98b3c1566a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/shreya/miniconda3/lib/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (2.2.2)\n",
      "Requirement already satisfied: bleach in /home/shreya/miniconda3/lib/python3.12/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/shreya/miniconda3/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/shreya/miniconda3/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shreya/miniconda3/lib/python3.12/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shreya/miniconda3/lib/python3.12/site-packages (from requests->kaggle) (3.7)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibULCmb3EBE_"
   },
   "source": [
    "#### Set Up Kaggle API Credentials\n",
    "1. Go to Kaggle's website and sign up.\n",
    "2. Go to \"My Account\" (click on your profile picture in the top right corner and then on \"My Account\").\n",
    "3. Go to \"Settings\"\n",
    "4. Scroll down to the \"API\" section and click on \"Create New API Token\". This will download a file called kaggle.json.\n",
    "5. Place the kaggle.json file in the .kaggle directory in your home directory. You can do this with the following commands:\n",
    "```sh\n",
    "    mkdir -p ~/.kaggle\n",
    "    mv /path/to/kaggle.json ~/.kaggle/\n",
    "    chmod 600 ~/.kaggle/kaggle.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtxKeRzXEBFB"
   },
   "source": [
    "#### Joining Relevant Competition on Kaggle\n",
    "1. Make sure you have logged into kaggle with the same account the API key has been generated for.\n",
    "2. Go to https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques and click on \"Join Competition\".\n",
    "3. This way, the regression dataset (House Price Prediction) will download seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52qLgk2REBFE"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR0cFJGaEBFG"
   },
   "source": [
    "#### Download the Dataset\n",
    "Now you can use the Kaggle API to download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NKbOKyYaEBFI",
    "outputId": "e135838f-a791-45a0-a656-b96d7c71374b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "filename = 'breast-cancer-wisconsin-data.zip'\n",
    "os.makedirs(\"classification\", exist_ok=True)\n",
    "for root, dirs, file in os.walk(\"./\", topdown=True):\n",
    "    if filename in file:\n",
    "        break\n",
    "else:\n",
    "    !kaggle datasets download -d uciml/breast-cancer-wisconsin-data\n",
    "    !mv breast-cancer-wisconsin-data.zip 'classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w6xVIkFbEBFJ",
    "outputId": "4d0308b4-2daf-445b-cc2e-45ffcf1f737d"
   },
   "outputs": [],
   "source": [
    "for root, dirs, file in os.walk(\"./\", topdown=True):\n",
    "    if 'data.csv' in file:\n",
    "        break\n",
    "else:\n",
    "    !unzip classification/breast-cancer-wisconsin-data.zip -d classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/shreya/.local/share/pipx/venvs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/shreya/.local/share/pipx/venvs/notebook/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRZqKc7KEBFK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVyw5AElEBFM"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tml27w0aEBFN"
   },
   "source": [
    "#### 1. Loading a dataset\n",
    "The breast cancer dataset, provided by scikit-learn, is a widely used dataset in the field of machine learning and data science. This dataset contains measurements of various features of cell nuclei present in breast cancer biopsies. It is commonly used for binary classification tasks to distinguish between malignant (cancerous) and benign (non-cancerous) tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35NRxFexEBFN",
    "outputId": "77d1a6b5-4a44-488e-a1ee-7e0500eafe48"
   },
   "outputs": [],
   "source": [
    "data = \"classification/data.csv\"\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1amF-ImEBFO",
    "outputId": "f04e38ab-456d-4b58-a4b9-cabb8225ac07"
   },
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7oM7calEBFP"
   },
   "source": [
    "#### 2. Splitting the dataset into training, validation, and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWXBzgt0EBFQ",
    "outputId": "c1b76ea5-11bf-40d3-f9b4-3e4643f07c84"
   },
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"Display summary statistics: \\n\",df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zlr1wsjJEBFR",
    "outputId": "a8ad8e05-fe39-40e3-f8af-ab6488e57ce1"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxoXDnKGEBFS"
   },
   "source": [
    "### Data Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mr_ufbzQEBFT",
    "outputId": "3e23e275-d4d9-4604-f291-f6dabbf55b3f"
   },
   "outputs": [],
   "source": [
    "#Drop columns which\n",
    "\n",
    "df = df.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Convert 'diagnosis' column to binary\n",
    "y = y.replace({'M': 1, 'B': 0})\n",
    "\n",
    "print(\"target: \\n\",y.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjq5ECr_EBFU",
    "outputId": "b83e1758-13ed-4c6e-807a-c6070696520d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training, validation, and test sets (70%, 10%, 20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.66, random_state=42)\n",
    "\n",
    "# Check the shapes of the splits\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmIk-YFcEBFV"
   },
   "source": [
    "#### 3. Training different classification models\n",
    "In this section, we will demonstrate how to initialize and train different classification models using scikit-learn. While we won't go into the detailed workings of these models, it's important to know that there are multiple algorithms available for classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IM5xEtdIEBFW",
    "outputId": "7b7c5012-3952-4d7b-89fe-ca00202110c0"
   },
   "outputs": [],
   "source": [
    "# Initialize and train a Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vizcmH6FEBFX",
    "outputId": "52c57417-0215-4847-a53d-993b33de404d"
   },
   "outputs": [],
   "source": [
    "# Initialize and train DecisionTree Model\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RczZANmEBFX",
    "outputId": "95c280a1-576d-4938-8928-8ccab9c75b6b"
   },
   "outputs": [],
   "source": [
    "# Initialize and train SVM Model\n",
    "svm_clf = SVC(random_state=42)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDwq8_-1EBFY"
   },
   "source": [
    "If you wish to look at the predictions of each model separately, try executing `model_name.predict(X_val)`.\n",
    "\n",
    "These predictions are then compared to `y_val` for better insigths at how the model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XSBrisQEBFY"
   },
   "source": [
    "#### 4. Visualizing the metrics for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmUfhEubEBFZ",
    "outputId": "b29f65ee-906e-4b7a-f4ae-68177a8007de"
   },
   "outputs": [],
   "source": [
    "# Summary of performance metrics\n",
    "metrics = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'SVM'],\n",
    "    'Accuracy': [accuracy_score(y_val, log_reg.predict(X_val)),\n",
    "                 accuracy_score(y_val, tree_clf.predict(X_val)),\n",
    "                 accuracy_score(y_val, svm_clf.predict(X_val))],\n",
    "    'Precision': [precision_score(y_val, log_reg.predict(X_val)),\n",
    "                  precision_score(y_val, tree_clf.predict(X_val)),\n",
    "                  precision_score(y_val, svm_clf.predict(X_val))],\n",
    "    'Recall': [recall_score(y_val, log_reg.predict(X_val)),\n",
    "               recall_score(y_val, tree_clf.predict(X_val)),\n",
    "               recall_score(y_val, svm_clf.predict(X_val))],\n",
    "    'F1-Score': [f1_score(y_val, log_reg.predict(X_val)),\n",
    "                 f1_score(y_val, tree_clf.predict(X_val)),\n",
    "                 f1_score(y_val, svm_clf.predict(X_val))]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVwmQ-W-EBFa"
   },
   "source": [
    "Based on the performance metrics, it appears that the **Logistic Regression** model is the best fit for this data. It achieved the highest accuracy, precision , recall, and F1-score are also superior compared to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpSc516fEBFa"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1BEJVsbEBFb",
    "outputId": "cb4c88c5-100e-4dd7-9a54-02a4030d117c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "filename = 'house-prices-advanced-regression-techniques.zip'\n",
    "os.makedirs('regression', mode=0o777, exist_ok=True)\n",
    "for root, dirs, file in os.walk(\"./\", topdown=True):\n",
    "    if filename in file:\n",
    "        break\n",
    "else:\n",
    "    !kaggle competitions download -c house-prices-advanced-regression-techniques\n",
    "    !mv house-prices-advanced-regression-techniques.zip regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myM3WlZrEBFc",
    "outputId": "a224431a-8123-49f3-f2c6-0637f3ff34eb"
   },
   "outputs": [],
   "source": [
    "if len(os.listdir(\"regression/\")) == 1:\n",
    "    ! unzip 'regression/house-prices-advanced-regression-techniques.zip' -d 'regression/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kj8O-AB5EBFe",
    "outputId": "87abf8d0-1efb-441f-fabc-58196e51afd0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regression/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8peSg277EBFf",
    "outputId": "ea0f2b0e-b005-4769-e1ce-0742fe7c19b9"
   },
   "outputs": [],
   "source": [
    "# Define the target variable and features\n",
    "target = 'SalePrice'\n",
    "features = df.drop(columns=[target])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqeiG8raEBFg",
    "outputId": "d945e4e2-f951-4ba8-c71c-78200420ba1d"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=[target])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8P7EUazKEBFg",
    "outputId": "e6ac58c3-35b6-457e-c9e1-6231258b54d3"
   },
   "outputs": [],
   "source": [
    "# drop columns with all NaN's\n",
    "df = df.dropna(axis=1)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vicGZ5juEBFh"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocess the data: scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_guGSshEBFi",
    "outputId": "d1bebb8c-16d0-4941-c175-9a09f94140f8"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATstQrH3EBFx",
    "outputId": "ec435e46-21e1-441a-9c76-60d8443a56ef"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9BTKuL-EBFy"
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syLpDVk4EBFy",
    "outputId": "a104e579-4200-4e2b-c937-18653fc5a891"
   },
   "outputs": [],
   "source": [
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G91_KkOEBFz",
    "outputId": "a0ccec40-e73d-45d1-cba7-87dc4c35ba75"
   },
   "outputs": [],
   "source": [
    "if r2 > 0.8:\n",
    "    print(\"The model explains a high proportion of the variance in house prices, suggesting a strong fit.\")\n",
    "elif r2 > 0.5:\n",
    "    print(\"The model explains a moderate proportion of the variance in house prices, indicating a reasonable fit.\")\n",
    "else:\n",
    "    print(\"The model explains a low proportion of the variance in house prices, indicating that it may not fit the data well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QgDqoZhEBFz"
   },
   "source": [
    "## That's the end of this notebook, hope you had a fun learning experience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
